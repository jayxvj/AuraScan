# ğŸ§  AuraScan

This repository contains an **AI-powered AR Health Scanner and Virtual Try-On System**.  
It combines **computer vision, deep learning, and augmented reality** to detect human health cues, recognize objects, and overlay virtual items in real-time.

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ model/ # Pre-trained & custom-trained ML/DL models
â”œâ”€â”€ snaps/ # Example screenshots & output snapshots
â”œâ”€â”€ tryon resources/ # Glasses / accessories / virtual objects for AR TryOn
â”œâ”€â”€ error_handling.py # Centralized error handling & logging
â”œâ”€â”€ health_scanner.py # AR Health Scanner (face, posture, nails, skin)
â”œâ”€â”€ obj_recog.py # Object recognition using YOLO / vision models
â”œâ”€â”€ skin_scan.py # Skin condition prediction (CNN)
â”œâ”€â”€ train_labels.py # Dataset training & label mapping
â”œâ”€â”€ tryon.py # AR Virtual Try-On engine
â””â”€â”€ README.md # Project documentation


---

## ğŸš€ Features

- **Real-time AR Health Scanner**  
  - Eye fatigue detection  
  - Posture analysis (spine, shoulders, head tilt)  
  - Nail & skin health checks  

- **Skin Condition Classification**  
  - Uses a CNN trained on medical skin datasets  
  - Detects and classifies conditions with accuracy reports  

- **Object Recognition**  
  - YOLOv8 / Mediapipe-based real-time recognition  
  - Identifies daily objects, living/non-living items  

- **Virtual Try-On (AR)**  
  - Overlay glasses / accessories on userâ€™s face  
  - Uses `tryon resources/` assets  

- **Robust Error Handling**  
  - Centralized logging in `error_handling.py`  

- **Training Utilities**  
  - `train_labels.py` handles dataset preprocessing & label mappings  

---

## ğŸ› ï¸ Installation

### Requirements
- Python 3.9+
- OpenCV
- Mediapipe
- TensorFlow / Keras
- NumPy
- Ultralytics YOLO (optional for `obj_recog.py`)

### Install dependencies
```bash
pip install -r requirements.txt
